# Aicup_drone-2022 ç„¡äººæ©Ÿé£›è¡Œè¼‰å…·ä¹‹æ™ºæ…§è¨ˆæ•¸ç«¶è³½

## æŒ‡å°æ•™æˆ: åŠ‰å®—æ¦®  

## éšŠå: TEAM_2060

## éšŠé•· : [é»ƒè£•èŠ³](https://github.com/Andrewhsin)  çµ„å“¡: è˜‡éƒå®¸, æ—å³»å®‰, [é™³æŸç‘‹](https://github.com/bobo0303), è³´äº­æ—­  

Implementation of paper - [YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors](https://arxiv.org/abs/2207.02696)

Competitions - [Aicup_drone-2022](https://tbrain.trendmicro.com.tw/Competitions/Details/25)

<img src="./figure/img10011.png" height="480">

```
â”œâ”€â”€ README.md    

ä¸»è¦è¨“ç·´ç¨‹å¼ç¢¼
â”œâ”€â”€ runs
â”‚   â”œâ”€â”€ train               å­˜æ”¾è¨“ç·´æ¬Šé‡è³‡æ–™å¤¾
â”‚   â”œâ”€â”€ detect              å­˜æ”¾ public & private è¼¸å‡ºè³‡æ–™å¤¾ 
â”‚   â””â”€â”€ save                å­˜æ”¾ public & private .csv è¼¸å‡ºè³‡æ–™å¤¾ 
â”œâ”€â”€ make_txt.py             æŠŠä¸»è¾¦å–®ä½çµ¦çš„csvè½‰æˆç›¸é—œæ ¼å¼
â”œâ”€â”€ ç›®æ¨™æ•¸æ“šé›†
â”‚   â”œâ”€â”€ train.txt           è½‰æª”å¾Œçš„è¨“ç·´æ¨™ç±¤æª”
â”‚   â”œâ”€â”€ val.txt             è½‰æª”å¾Œçš„é©—è­‰æ¨™ç±¤æª” 
â”‚   â”œâ”€â”€ train               å­˜æ”¾ train çš„ image & labels è³‡æ–™å¤¾
â”‚   â””â”€â”€ save                å­˜æ”¾ val çš„ image & labels è³‡æ–™å¤¾
â”œâ”€â”€ train.py                åŸ·è¡Œè¨“ç·´åŠå…¶ä»–åƒæ•¸èª¿æ•´
â”œâ”€â”€ runs
â”‚   â”œâ”€â”€ train               å­˜æ”¾è¨“ç·´æ¬Šé‡è³‡æ–™å¤¾
â”‚   â”œâ”€â”€ detect              å­˜æ”¾ public & private è¼¸å‡ºè³‡æ–™å¤¾ 
â”‚   â””â”€â”€ save                å­˜æ”¾ public & private .csv è¼¸å‡ºè³‡æ–™å¤¾ 
â”œâ”€â”€ data_arg
â”‚   â”œâ”€â”€ ENSEMBLE            ä¸åŒæ¨¡å‹ & csv çµåˆ
â”‚   â”œâ”€â”€ AUGMENTATION_       è³‡æ–™æ“´å¢ã€ç¿»è½‰ã€æ—‹è½‰       
â”‚   â””â”€â”€ PSUEDO_LABEL        å°‡è¼¸å‡ºçµæœ PSUEDO_LABEL
â”‚
â”œâ”€â”€ log                     è¨“ç·´losså¯è¦–åŒ–(tensorboard)
â”œâ”€â”€ wandb                   è¨“ç·´losså¯è¦–åŒ–(wandb)
â”œâ”€â”€ yolov7.pt               YOLOv7 pretrained model
â”œâ”€â”€ yolov7_w6.pt            YOLOv7_w6 pretrained model   

ä¸»è¦æ¸¬è©¦ç¨‹å¼ç¢¼

â”œâ”€â”€ detect.py               è¼¸å‡º public & private è³‡æ–™é›†
â”œâ”€â”€ csv_output.py             å°‡ public & private è³‡æ–™é›†çµæœè½‰ç‚º.csv  

```







## Web Demo

- Integrated into [Huggingface Spaces ğŸ¤—](https://huggingface.co/spaces/akhaliq/yolov7) using [Gradio](https://github.com/gradio-app/gradio). Try out the Web Demo [![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/akhaliq/yolov7)

## Performance 


## Installation

Docker environment (recommended)
<details><summary> <b>Expand</b> </summary>

```
# create the docker container, you can change the share memory size if you have more.
nvidia-docker run --name yolov7 -it -v your_coco_path/:/coco/ -v your_code_path/:/yolov7 --shm-size=64g nvcr.io/nvidia/pytorch:21.08-py3

# apt install required packages
apt update
apt install -y zip htop screen libgl1-mesa-glx

# pip install required packages
pip install seaborn thop

# go to code folder
cd /yolov7
```

</details>

## Training

1. æº–å‚™Ground truth label (`train.txt`/`val.txt`)  
   ä¸¦å°‡è¨“ç·´åœ–ç‰‡æ”¾å…¥trainingè³‡æ–™å¤¾ï¼Œlabelæ ¼å¼å¦‚ä¸‹
    ```
    E:/Aicup_drone/image_path/train/images/img10001.jpg
    E:/Aicup_drone/image_path/train/images/img10002.jpg
    E:/Aicup_drone/image_path/train/images/img10003.jpg
    E:/Aicup_drone/image_path/train/images/img10004.jpg
    ...
    ```


Single GPU training

```
python train.py --workers 8 --device 0 --batch-size 32 --data data/coco.yaml --img 640 640 --cfg cfg/training/yolov7.yaml --weights '' --name yolov7 --hyp data/hyp.scratch.p5.yaml

python train.py --workers 8 --device 0 --batch-size 32 --data data/coco.yaml --img 640 640 --cfg cfg/training/yolov7x.yaml --weights '' --name yolov7x --hyp data/hyp.scratch.p5.yaml
```

Multiple GPU training

```
python -m torch.distributed.launch --nproc_per_node 4 --master_port 9527 train.py --workers 8 --device 0,1,2,3 --sync-bn --batch-size 128 --data data/coco.yaml --img 640 640 --cfg cfg/training/yolov7.yaml --weights '' --name yolov7 --hyp data/hyp.scratch.p5.yaml

python -m torch.distributed.launch --nproc_per_node 4 --master_port 9527 train.py --workers 8 --device 0,1,2,3 --sync-bn --batch-size 128 --data data/coco.yaml --img 640 640 --cfg cfg/training/yolov7x.yaml --weights '' --name yolov7x --hyp data/hyp.scratch.p5.yaml
```

## Inference

## 1.1 ç›¸é—œæ¸¬è©¦åƒæ•¸è¨­å®š
1. [AI CUP ç«¶è³½å ±å‘Š](https://drive.google.com/file/d/1puLpWeq7S_aKfyerbI9787HfJ-Fl19_l/view?usp=sharing)  
2. [AI CUP å¯¦é©—è¨˜éŒ„](https://drive.google.com/file/d/1tNn-kyzaWkC-EPw4iEtFYSf3xShvJVQq/view?usp=sharing)  
3. [Public data](https://drive.google.com/drive/folders/1lx4rOFNm1ayZOFxhmhru6AoiEg05JO4O?usp=sharing)
4. [Private data](https://drive.google.com/drive/folders/1n52IcT7IGtNQ5OG2wetj__WAki9ajiRO?usp=sharing)
5. æ¸¬è©¦æ™‚ä¸éœ€è¦æ›´æ”¹ç›¸é—œè·¯å¾‘ï¼Œåªé ˆç¢ºå®šæ‰€æœ‰ç›¸å°è·¯å¾‘å…§æ˜¯å¦æœ‰åœ–ç‰‡å³å¯  
6. æ¸¬è©¦æ™‚æ‰€æœ‰æ›´æ”¹åƒæ•¸çš„åœ°æ–¹éƒ½åœ¨`åç¨±.yaml`é€²è¡Œæ›´æ”¹  
7. é è¨­æ¸¬è©¦è³‡æ–™è·¯å¾‘: `./inference/images/`
8. é è¨­æ¸¬è©¦çµæœè·¯å¾‘: `./runs/detect/`

`python detect.py --weights yolov7.pt --conf 0.25 --img-size 640 --source inference/`

<img src="./figure/img1001.png" height="480">


## 2.2 æ¸¬è©¦åˆ†æ•¸
- æˆ‘å€‘æ¯æ¬¡ä¸Šå‚³åˆ†æ•¸éƒ½æœƒç•™ä¸‹ç•¶æ¬¡æ¸¬è©¦çš„åƒæ•¸ç´°ç¯€ã€åµæ¸¬çµæœåœ–èˆ‡æ¸¬è©¦åˆ†æ•¸  
  è‹¥æœ‰éœ€è¦å¯ä»¥è¯çµ¡æˆ‘å€‘ å†æŠŠæ‰€æœ‰å®Œæ•´æª”æ¡ˆåˆ†æ‰¹å‚³é€
  
  <img src="./figure/203.png" height="480">



## Citation

```
@article{wang2022yolov7,
  title={{YOLOv7}: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors},
  author={Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark},
  journal={arXiv preprint arXiv:2207.02696},
  year={2022}
}
```


## Acknowledgements

<details><summary> <b>Expand</b> </summary>

* [https://github.com/AlexeyAB/darknet](https://github.com/AlexeyAB/darknet)
* [https://github.com/WongKinYiu/yolov7](https://github.com/WongKinYiu/yolov7)
* [https://github.com/WongKinYiu/yolor](https://github.com/WongKinYiu/yolor)
* [https://github.com/WongKinYiu/PyTorch_YOLOv4](https://github.com/WongKinYiu/PyTorch_YOLOv4)
* [https://github.com/WongKinYiu/ScaledYOLOv4](https://github.com/WongKinYiu/ScaledYOLOv4)
* [https://github.com/Megvii-BaseDetection/YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)
* [https://github.com/ultralytics/yolov3](https://github.com/ultralytics/yolov3)
* [https://github.com/ultralytics/yolov5](https://github.com/ultralytics/yolov5)
* [https://github.com/DingXiaoH/RepVGG](https://github.com/DingXiaoH/RepVGG)
* [https://github.com/JUGGHM/OREPA_CVPR2022](https://github.com/JUGGHM/OREPA_CVPR2022)

</details>
